{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "from collections import defaultdict\n",
    "from itertools import product, combinations\n",
    "from operator import itemgetter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# These are the functions you need to read in the data. You need to have the datafiles in a data folder that is in\n",
    "# the directory you are working in\n",
    "#LINK IM USING FOR K-NN https://stackabuse.com/k-nearest-neighbors-algorithm-in-python-and-scikit-learn/\n",
    "\n",
    "\n",
    "def parse(path):\n",
    "    g = gzip.open(path, 'rb')\n",
    "    for l in g:\n",
    "        yield eval(l)\n",
    "\n",
    "def getData(name, attributes):\n",
    "    i = 0\n",
    "    dic = {}\n",
    "    path = 'data/reviews_%s_5.json.gz' % name\n",
    "    for line in parse(path):\n",
    "        filtered = {}\n",
    "        for k in line.keys():\n",
    "            if k in attributes:\n",
    "                filtered[k] = line[k]\n",
    "            else:\n",
    "                continue\n",
    "        \n",
    "        dic[i] = filtered\n",
    "        i += 1\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# These are one of the three names you can choose to read the dataset from\n",
    "names = ['Digital_Music', 'Kindle_Store', 'Video_Games']\n",
    "\n",
    "# These are all the possible attributes that our datapoints can have. Lots of them are not that useful for us. So during\n",
    "# the reading of the datafile you have to specify which of these attributes you want to include. For our purposes,\n",
    "# only reviewerID, asin (product ID) and overall will be helpful. But I included them all, just in case.\n",
    "attributes = ['reviewerID', 'asin', 'reviewerName', 'helpful', 'reviewText', 'overall', 'summary', \n",
    "              'unixReviewTime', 'reviewTime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "run_control": {
     "marked": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# You read in the data for example like this:\n",
    "data = getData('Digital_Music', ['reviewerID', 'asin', 'overall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "run_control": {
     "marked": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'reviewerID': 'A3EBHHCZO6V2A4', 'asin': '5555991584', 'overall': 5.0}\n",
      "{'reviewerID': 'AZPWAXJG9OJXV', 'asin': '5555991584', 'overall': 5.0}\n",
      "{'reviewerID': 'A38IRL0X2T4DPF', 'asin': '5555991584', 'overall': 5.0}\n",
      "{'reviewerID': 'A22IK3I6U76GX0', 'asin': '5555991584', 'overall': 5.0}\n",
      "{'reviewerID': 'A1AISPOIIHTHXX', 'asin': '5555991584', 'overall': 4.0}\n"
     ]
    }
   ],
   "source": [
    "# This is what our data will look like. You have a dictionary with integers as keys [0,1,2,3,4...], and as values one \n",
    "# datapoint. Each datapoint in itself is a dictionary, with as keys the attribute, and as value the value of that attribute.\n",
    "for i in range(5):\n",
    "    print(data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def split_data(data, test_ratio=0.1):\n",
    "    reviewers = set()\n",
    "    for i in data.items():\n",
    "        reviewers.add(i[1]['reviewerID'])\n",
    "    \n",
    "    l = len(reviewers)\n",
    "    test_reviewers = set(random.sample(reviewers, int(l*test_ratio)))\n",
    "    train_reviewers = reviewers - test_reviewers\n",
    "    \n",
    "    train_data = {k:v for k,v in data.items() if v['reviewerID'] in train_reviewers}\n",
    "    test_data = {k:v for k,v in data.items() if v['reviewerID'] in test_reviewers}\n",
    "    \n",
    "    \n",
    "    tr = len(train_data)\n",
    "    te = len(test_data)\n",
    "    print('There are %s train reviews' %tr)\n",
    "    print('There are %s test reviews' %te)\n",
    "    \n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 58210 train reviews\n",
      "There are 6496 test reviews\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = split_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "run_control": {
     "marked": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of colums in training Dataframe :  3\n",
      "Number of rows in training Dataframe :  58210\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>A3EBHHCZO6V2A4</td>\n",
       "      <td>5555991584</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>AZPWAXJG9OJXV</td>\n",
       "      <td>5555991584</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>A38IRL0X2T4DPF</td>\n",
       "      <td>5555991584</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>A22IK3I6U76GX0</td>\n",
       "      <td>5555991584</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>A1AISPOIIHTHXX</td>\n",
       "      <td>5555991584</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin  overall\n",
       "0  A3EBHHCZO6V2A4  5555991584      5.0\n",
       "1   AZPWAXJG9OJXV  5555991584      5.0\n",
       "2  A38IRL0X2T4DPF  5555991584      5.0\n",
       "3  A22IK3I6U76GX0  5555991584      5.0\n",
       "4  A1AISPOIIHTHXX  5555991584      4.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train = pd.DataFrame.from_dict(train_data, orient='index')\n",
    "ds_test = pd.DataFrame.from_dict(test_data, orient='index')\n",
    "\n",
    "print('Number of colums in training Dataframe : ', len(ds_train.columns))\n",
    "print('Number of rows in training Dataframe : ', len(ds_train.index))\n",
    "ds_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['A3EBHHCZO6V2A4' '5555991584' 5.0]\n",
      " ['AZPWAXJG9OJXV' '5555991584' 5.0]\n",
      " ['A38IRL0X2T4DPF' '5555991584' 5.0]\n",
      " ['A22IK3I6U76GX0' '5555991584' 5.0]\n",
      " ['A1AISPOIIHTHXX' '5555991584' 4.0]\n",
      " ['A2P49WD75WHAG5' '5555991584' 5.0]]\n",
      "[['A1BXA3SM3AJOKL' '5555991584' 4.0]\n",
      " ['A3RNC9BGR4J1ZF' 'B0000000ZW' 5.0]\n",
      " ['APN6DO7VHDLTN' 'B00000016T' 5.0]\n",
      " ['A31I5XTQ5BAR9F' 'B00000016T' 5.0]\n",
      " ['A1USDS1D8MZJUA' 'B00000016T' 5.0]\n",
      " ['A23LCEFE2BWE5F' 'B00000016T' 5.0]]\n"
     ]
    }
   ],
   "source": [
    "X_train = ds_train.iloc[:,:].values\n",
    "X_test = ds_test.iloc[:,:].values\n",
    "\n",
    "print(X_train[:6])\n",
    "print(X_test[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def cosine_similarity(p,q):\n",
    "    d = sum(pi * qi for pi,qi in zip(p, q))\n",
    "    mag_p = math.sqrt(sum([pi**2 for pi in p]))\n",
    "    mag_q = math.sqrt(sum([qi**2 for qi in q]))\n",
    "    sim = d / ( mag_p * mag_q)\n",
    "    return sim\n",
    "\n",
    "def euclidean_similarity(p, q):\n",
    "    dist = math.sqrt(sum((pi-qi)**2 for pi,qi in zip(p, q)))\n",
    "    sim = 1 / (1+dist)\n",
    "    return sim    \n",
    "\n",
    "def pearson_correlation(p,q):\n",
    "    # this code does not scale well to large datasets. In the following, we rely on \n",
    "    # scipy.spatial.distance.correlation() to compute long vectors\n",
    "    if len(p) > 99:\n",
    "        return 1 - distance.correlation(p,q)        \n",
    "    \n",
    "    p_mean = sum(p) / len(p)\n",
    "    p_deviations = [(pi-p_mean) for pi in p]\n",
    "    \n",
    "    q_mean = sum(q) / len(q)\n",
    "    q_deviations = [(qi-q_mean) for qi in q]\n",
    "    \n",
    "    cov = sum(pd * qd for pd,qd in zip(p_deviations, q_deviations))\n",
    "        \n",
    "    sds_product = math.sqrt(sum((pd)**2 for pd in p_deviations) * sum((qd)**2 for qd in q_deviations))\n",
    "    \n",
    "    if sds_product != 0:\n",
    "        r = cov / sds_product\n",
    "    else:\n",
    "        r = 0\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def calc_similarity(user2product, target, other_user, sim_measure, threshold=0):\n",
    "    # found some explanation here https://towardsdatascience.com/introduction-to-recommender-systems-6c66cf15ada\n",
    "    \n",
    "    shared = list(set(user2product[target].keys()).intersection(set(user2product[other_user].keys())))\n",
    "    \n",
    "    if len(shared) <= threshold:\n",
    "        return 0\n",
    "    \n",
    "    target_ratings = [v for k,v in user2product[target].items() if k in shared]# for i in [target, other_user]]\n",
    "    other_user_ratings = [v for k,v in user2product[other_user].items() if k in shared]\n",
    "    \n",
    "    weight = len(shared)/len(user2product[target])\n",
    "    similarity = weight*sim_measure(target_ratings, other_user_ratings)\n",
    "    \n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "run_control": {
     "marked": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "user2item = defaultdict(dict)\n",
    "for reviewerID, asin, overall in X_train:\n",
    "    user2item[reviewerID][asin] = overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of users: 4987\n",
      "no of reviews in user 1: 91\n"
     ]
    }
   ],
   "source": [
    "print(\"no. of users:\", len(user2item))\n",
    "print(\"no of reviews in user 1:\", len(list(user2item.items())[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of items: 3568\n"
     ]
    }
   ],
   "source": [
    "item2user = defaultdict(dict)\n",
    "for reviewerID, asin, overall in X_train:\n",
    "    item2user[asin][reviewerID] = overall\n",
    "    \n",
    "print(\"no. of items:\", len(item2user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'calculate_similarity' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-2c78cd679359>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0msimilarities\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmeasure\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser2item\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mid1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser2item\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0msimilarities\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmeasure\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser2item\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#print(similarities[\"cosine\"].items())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'calculate_similarity' is not defined"
     ]
    }
   ],
   "source": [
    "# Calculate the similarities (NB: this can take a minute)\n",
    "measure2function = {\"euclidean\" : euclidean_similarity, \"cosine\": cosine_similarity, \"pearson\": pearson_correlation}\n",
    "\n",
    "similarities = {\"euclidean\" : dict(), \"cosine\": dict(), \"pearson\": dict()}\n",
    "for measure, function in measure2function.items():\n",
    "    similarities[measure] = dict([(a,dict()) for a in list(user2item.keys())[:40]])\n",
    "    for id1, id2, in combinations(list(user2item.keys())[:40], 2):\n",
    "        similarities[measure][id1][id2] = calc_similarity(user2item, id1, id2, function)\n",
    "        \n",
    "#print(similarities[\"cosine\"].items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def recommend(userid, sim_measure, user2product, k):\n",
    "    \"\"\"This function takes a user id, similarity measure, the user2product dictionary, and k as input. It calculates the\n",
    "    k most similar users. It outputs a dictionary, with as keys tuples containing the k similar users ID and their\n",
    "    similarity, and as values a dictionary containing the ratings for all of their items\"\"\"\n",
    "    reviewers = [user for user in user2product.keys() if user != userid]\n",
    "    similarities = [(other_user, calc_similarity(user2product, userid, other_user, sim_measure)) for other_user in reviewers]\n",
    "    k_similarities = sorted(similarities, key = lambda x: x[1], reverse=True)[:k]\n",
    "    output = dict()\n",
    "    for user_tup in k_similarities:\n",
    "        output[user_tup] = user2product[user_tup[0]]\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "#recommend('A3EBHHCZO6V2A4', cosine_similarity, user2product, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making a similarity matrix...\n",
      "Setting up the 10 neighbourhoods...\n",
      "Recommending...\n",
      "Item B0000004VW is estimated to be rated: 5.0\n",
      "Item B000000518 is estimated to be rated: 5.0\n",
      "Item B00000053X is estimated to be rated: 5.0\n",
      "Item B00000064F is estimated to be rated: 5.0\n",
      "Item B0000009OU is estimated to be rated: 5.0\n",
      "Item B000000HLL is estimated to be rated: 5.0\n",
      "Item B000000ORB is estimated to be rated: 5.0\n",
      "Item B000000OYK is estimated to be rated: 5.0\n",
      "Item B000000WGP is estimated to be rated: 5.0\n",
      "Item B000000YDT is estimated to be rated: 5.0\n"
     ]
    }
   ],
   "source": [
    "class kNN(object):\n",
    "    \"\"\" k-Nearest Neighbour \"\"\"\n",
    "    \n",
    "    def __init__(self, x2y: dict, sim_measure, name=None, k = 10):\n",
    "        self.x2y = x2y                     # For example, user2item matrix\n",
    "        self.k = k\n",
    "        self.sim_measure = sim_measure     # Like cosine similarity\n",
    "        if name:\n",
    "            self.similarities=pickle.load(open(f\"data/{name}_similarities.pkl\", 'rb'))\n",
    "            self.neighborhood=pickle.load(open(f\"data/{name}_neighboorhood.pkl\", 'rb'))\n",
    "        else:\n",
    "            self.similarities = None   # If the similarities are already stored\n",
    "            self.neighborhood = None   # Likewise\n",
    "        self.target_vector = None\n",
    "    \n",
    "    def find_id_similarities(self, an_id):\n",
    "        \"\"\" For user-to-user part\"\"\"\n",
    "        sims = dict()\n",
    "        for id1, id2 in product([target], list(x2y.keys())[:40]):\n",
    "            sims[id2] = calc_similarity(x2y, id1, id2, self.sim_measure)\n",
    "        return sorted(list(sims.items()), key=lambda x:x[1], reverse = True)[:k]\n",
    "    \n",
    "    def find_all_similarities(self, reset = False):\n",
    "        \"\"\" For item-to-item part\"\"\"\n",
    "        print(\"Making a similarity matrix...\")\n",
    "        if not reset:\n",
    "            return\n",
    "        sims = defaultdict(dict)\n",
    "        for id1, id2 in combinations(self.x2y.keys(), 2):\n",
    "            sims[id1][id2] = calc_similarity(self.x2y, id1, id2, self.sim_measure)\n",
    "        self.similarities = sims\n",
    "    \n",
    "    def get_neighborhoods(self, reset = False):\n",
    "        \"\"\" For every x, gets the other y similarities and makes it a dictionary\"\"\"\n",
    "        print(f\"Setting up the {self.k} neighbourhoods...\")\n",
    "        if not reset:\n",
    "            return\n",
    "        self.neighborhood = dict()\n",
    "        for x in self.similarities.keys():\n",
    "            self.neighborhood[x] = dict(sorted(self.similarities[x].items(),\n",
    "                                               key = itemgetter(1),\n",
    "                                               reverse = True)[:self.k])\n",
    "    \n",
    "    def built_target(self, an_id):\n",
    "        \"\"\" Makes a target vector from everything the user didn't rate\"\"\"\n",
    "        self.target_vector = list()\n",
    "        for ID, group in self.neighborhood.items():\n",
    "            if an_id not in group.keys():\n",
    "                self.target_vector.append(ID)\n",
    "    \n",
    "    def getPredictionsForItems(self, an_id, x):\n",
    "        \"\"\" Creates rating predictions depending on the neighborhood of x\"\"\"\n",
    "        weigthed_scores = list()\n",
    "        similarities = list()\n",
    "        self.target_vector = list()\n",
    "        for item, sim in self.neighborhood[x].items():\n",
    "            if an_id in self.x2y[item]:\n",
    "                weigthed_scores.append(sim * self.x2y[item][an_id])\n",
    "                self.target_vector.append(item)\n",
    "                similarities.append(sim)\n",
    "        if not sum(similarities):\n",
    "            return 0\n",
    "        return float(f\"{sum(weigthed_scores) / sum(similarities):.2f}\")\n",
    "    \n",
    "    def recommend_item(self, an_id):\n",
    "        \"\"\" Gets the similarities, neighborhoods and the target vector\n",
    "        Then gets predictions according to the vector. Finally recommends the top\n",
    "        predictions.\"\"\"\n",
    "        self.find_all_similarities()\n",
    "        self.get_neighborhoods()\n",
    "        self.built_target(an_id)\n",
    "        print(\"Recommending...\")\n",
    "        recommendations = dict()\n",
    "        for x in self.target_vector:\n",
    "            recommendations[x] = self.getPredictionsForItems(an_id, x)\n",
    "        return dict(sorted(list(recommendations.items()), key=lambda x:x[1], reverse=True)[:10])\n",
    "    \n",
    "    def save_state(self, name):\n",
    "        \"\"\" To save the state to prevent recomputing each time\"\"\"\n",
    "        file_stream = open(f'data/{name}_similarities.pkl', 'wb')\n",
    "        file_stream2 = open(f'data/{name}_neighboorhood.pkl', 'wb')\n",
    "        pickle.dump(self.similarities, file_stream)\n",
    "        pickle.dump(self.neighborhood, file_stream2)\n",
    "    \n",
    "    def prep_evaluation(self, test_x2y):\n",
    "        test_train, test_test = split(test_x2y)\n",
    "        self.add_xs(test_Train)\n",
    "        self.find_all_similarities(True)\n",
    "        self.get_neighborhoods(True)\n",
    "    \n",
    "    def evaluation(self, test_x2y):\n",
    "        prep_evaluation(test_x2y)\n",
    "\n",
    "\n",
    "aKNN = kNN(item2user, pearson_correlation, name=\"item2user\")\n",
    "recs = aKNN.recommend_item('A3EBHHCZO6V2A4')\n",
    "for ID, rate in recs.items():\n",
    "    print(f\"Item {ID} is estimated to be rated: {rate}\")\n",
    "#print(list(aKNN.neighborhood.keys()))\n",
    "#print(list(aKNN.neighborhood.items())[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def find_similarities(target: str, x2y: defaultdict, measure) -> dict:\n",
    "    similarities = dict()\n",
    "    for id1, id2 in product([target], user2product.keys()):\n",
    "        similarities[id2] = calculate_similarity(x2y, id1, id2, measure)\n",
    "    return sorted(list(similarities.items()), key=lambda x:x[1], reverse = True)[:50]\n",
    "\n",
    "\n",
    "#find_similarities('A3EBHHCZO6V2A4', user2product, cosine_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
