{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import defaultdict\n",
    "from itertools import product, combinations\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the functions you need to read in the data. You need to have the datafiles in a data folder that is in\n",
    "# the directory you are working in\n",
    "#LINK IM USING FOR K-NN https://stackabuse.com/k-nearest-neighbors-algorithm-in-python-and-scikit-learn/\n",
    "\n",
    "\n",
    "def parse(path):\n",
    "    g = gzip.open(path, 'rb')\n",
    "    for l in g:\n",
    "        yield eval(l)\n",
    "\n",
    "def getData(name, attributes):\n",
    "    i = 0\n",
    "    dic = {}\n",
    "    path = 'data/reviews_%s_5.json.gz' % name\n",
    "    for line in parse(path):\n",
    "        filtered = {}\n",
    "        for k in line.keys():\n",
    "            if k in attributes:\n",
    "                filtered[k] = line[k]\n",
    "            else:\n",
    "                continue\n",
    "        \n",
    "        dic[i] = filtered\n",
    "        i += 1\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are one of the three names you can choose to read the dataset from\n",
    "names = ['Digital_Music', 'Kindle_Store', 'Video_Games']\n",
    "\n",
    "# These are all the possible attributes that our datapoints can have. Lots of them are not that useful for us. So during\n",
    "# the reading of the datafile you have to specify which of these attributes you want to include. For our purposes,\n",
    "# only reviewerID, asin (product ID) and overall will be helpful. But I included them all, just in case.\n",
    "attributes = ['reviewerID', 'asin', 'reviewerName', 'helpful', 'reviewText', 'overall', 'summary', \n",
    "              'unixReviewTime', 'reviewTime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# You read in the data for example like this:\n",
    "data = getData('Digital_Music', ['reviewerID', 'asin', 'overall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'reviewerID': 'A3EBHHCZO6V2A4', 'asin': '5555991584', 'overall': 5.0}\n",
      "{'reviewerID': 'AZPWAXJG9OJXV', 'asin': '5555991584', 'overall': 5.0}\n",
      "{'reviewerID': 'A38IRL0X2T4DPF', 'asin': '5555991584', 'overall': 5.0}\n",
      "{'reviewerID': 'A22IK3I6U76GX0', 'asin': '5555991584', 'overall': 5.0}\n",
      "{'reviewerID': 'A1AISPOIIHTHXX', 'asin': '5555991584', 'overall': 4.0}\n"
     ]
    }
   ],
   "source": [
    "# This is what our data will look like. You have a dictionary with integers as keys [0,1,2,3,4...], and as values one \n",
    "# datapoint. Each datapoint in itself is a dictionary, with as keys the attribute, and as value the value of that attribute.\n",
    "for i in range(5):\n",
    "    print(data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, test_ratio=0.1):\n",
    "    reviewers = set()\n",
    "    for i in data.items():\n",
    "        reviewers.add(i[1]['reviewerID'])\n",
    "    \n",
    "    l = len(reviewers)\n",
    "    test_reviewers = set(random.sample(reviewers, int(l*test_ratio)))\n",
    "    train_reviewers = reviewers - test_reviewers\n",
    "    \n",
    "    train_data = {k:v for k,v in data.items() if v['reviewerID'] in train_reviewers}\n",
    "    test_data = {k:v for k,v in data.items() if v['reviewerID'] in test_reviewers}\n",
    "    \n",
    "    \n",
    "    tr = len(train_data)\n",
    "    te = len(test_data)\n",
    "    print('There are %s train reviews' %tr)\n",
    "    print('There are %s test reviews' %te)\n",
    "    \n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 58114 train reviews\n",
      "There are 6592 test reviews\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = split_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of colums in Dataframe :  3\n",
      "Number of rows in Dataframe :  58114\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>A3EBHHCZO6V2A4</td>\n",
       "      <td>5555991584</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>AZPWAXJG9OJXV</td>\n",
       "      <td>5555991584</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>A38IRL0X2T4DPF</td>\n",
       "      <td>5555991584</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>A22IK3I6U76GX0</td>\n",
       "      <td>5555991584</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>A1AISPOIIHTHXX</td>\n",
       "      <td>5555991584</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin  overall\n",
       "0  A3EBHHCZO6V2A4  5555991584      5.0\n",
       "1   AZPWAXJG9OJXV  5555991584      5.0\n",
       "2  A38IRL0X2T4DPF  5555991584      5.0\n",
       "3  A22IK3I6U76GX0  5555991584      5.0\n",
       "4  A1AISPOIIHTHXX  5555991584      4.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train = pd.DataFrame.from_dict(train_data, orient='index')\n",
    "ds_test = pd.DataFrame.from_dict(test_data, orient='index')\n",
    "\n",
    "print('Number of colums in Dataframe : ', len(ds.columns))\n",
    "print('Number of rows in Dataframe : ', len(ds.index))\n",
    "ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['A3EBHHCZO6V2A4' '5555991584' 5.0]\n",
      " ['AZPWAXJG9OJXV' '5555991584' 5.0]\n",
      " ['A38IRL0X2T4DPF' '5555991584' 5.0]\n",
      " ['A22IK3I6U76GX0' '5555991584' 5.0]\n",
      " ['A1AISPOIIHTHXX' '5555991584' 4.0]\n",
      " ['A2P49WD75WHAG5' '5555991584' 5.0]]\n",
      "[['A3UBAZKS727Z0E' '5555991584' 5.0]\n",
      " ['A8MWQY1R5YE3M' 'B00000016T' 5.0]\n",
      " ['A38NQGQW63IQJJ' 'B00000016T' 5.0]\n",
      " ['A1LDAIGOQ6N4DW' 'B00000016T' 5.0]\n",
      " ['A5KJVGJ43ZDC9' 'B00000016T' 5.0]\n",
      " ['A22N03OBDDVSEB' 'B00000016T' 5.0]]\n"
     ]
    }
   ],
   "source": [
    "X_train = ds_train.iloc[:,:].values\n",
    "X_test = ds_test.iloc[:,:].values\n",
    "\n",
    "print(X_train[:6])\n",
    "print(X_test[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(p,q):\n",
    "    d = sum(pi * qi for pi,qi in zip(p, q))\n",
    "    mag_p = math.sqrt(sum([pi**2 for pi in p]))\n",
    "    mag_q = math.sqrt(sum([qi**2 for qi in q]))\n",
    "    sim = d / ( mag_p * mag_q)\n",
    "    return sim\n",
    "\n",
    "def euclidean_similarity(p, q):\n",
    "    dist = math.sqrt(sum((pi-qi)**2 for pi,qi in zip(p, q)))\n",
    "    sim = 1 / (1+dist)\n",
    "    return sim    \n",
    "\n",
    "def pearson_correlation(p,q):\n",
    "    # this code does not scale well to large datasets. In the following, we rely on \n",
    "    # scipy.spatial.distance.correlation() to compute long vectors\n",
    "    if len(p) > 99:\n",
    "        return 1 - distance.correlation(p,q)        \n",
    "    \n",
    "    p_mean = sum(p) / len(p)\n",
    "    p_deviations = [(pi-p_mean) for pi in p]\n",
    "    \n",
    "    q_mean = sum(q) / len(q)\n",
    "    q_deviations = [(qi-q_mean) for qi in q]\n",
    "    \n",
    "    cov = sum(pd * qd for pd,qd in zip(p_deviations, q_deviations))\n",
    "        \n",
    "    sds_product = math.sqrt(sum((pd)**2 for pd in p_deviations) * sum((qd)**2 for qd in q_deviations))\n",
    "    \n",
    "    if sds_product != 0:\n",
    "        r = cov / sds_product\n",
    "    else:\n",
    "        r = 0\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_similarity(user2product, target, other_user, sim_measure, threshold=0):\n",
    "    # found some explanation here https://towardsdatascience.com/introduction-to-recommender-systems-6c66cf15ada\n",
    "    \n",
    "    shared = list(set(user2product[target].keys()).intersection(set(user2product[other_user].keys())))\n",
    "    \n",
    "    if len(shared) <= threshold:\n",
    "        return 0\n",
    "    \n",
    "    target_ratings = [v for k,v in user2product[target].items() if k in shared]# for i in [target, other_user]]\n",
    "    other_user_ratings = [v for k,v in user2product[other_user].items() if k in shared]\n",
    "    \n",
    "    weight = len(shared)/len(user2product[target])\n",
    "    similarity = weight*sim_measure(target_ratings, other_user_ratings)\n",
    "    \n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "user2product = defaultdict(dict)\n",
    "for reviewerID, asin, overall in X_train:\n",
    "    user2product[reviewerID][asin] = overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of users: 4987\n",
      "no of reviews in user 1: 91\n"
     ]
    }
   ],
   "source": [
    "print(\"no. of users:\", len(user2product))\n",
    "print(\"no of reviews in user 1:\", len(list(user2product.items())[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of items: 3568\n"
     ]
    }
   ],
   "source": [
    "item2product = defaultdict(dict)\n",
    "for reviewerID, asin, overall in X_train:\n",
    "    item2product[asin][reviewerID] = overall\n",
    "    \n",
    "print(\"no. of items:\", len(item2product))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the similarities (NB: this can take a minute)\n",
    "measure2function = {\"euclidean\" : euclidean_similarity, \"cosine\": cosine_similarity, \"pearson\": pearson_correlation}\n",
    "\n",
    "similarities = {\"euclidean\" : dict(), \"cosine\": dict(), \"pearson\": dict()}\n",
    "for measure, function in measure2function.items():\n",
    "    similarities[measure] = dict([(a,dict()) for a in list(user2product.keys())[:40]])\n",
    "    for id1, id2, in combinations(list(user2product.keys())[:40], 2):\n",
    "        similarities[measure][id1][id2] = calculate_similarity(user2product, id1, id2, function)\n",
    "        \n",
    "#print(similarities[\"cosine\"].items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "class kNN(object):\n",
    "    \"\"\" k-Nearest Neighbour \"\"\"\n",
    "    \n",
    "    def __init__(self, x2y: dict, sim_measure:callable[(list, list), float], k = 10):\n",
    "        self.x2y = x2y\n",
    "        self.k = k\n",
    "        self.sim_measure = sim_measure\n",
    "    \n",
    "    def find_similarities(self, an_id):\n",
    "        similarities = dict()\n",
    "        for id1, id2 in product([target], list(user2product.keys())[:40]):\n",
    "            similarities[id2] = calculate_similarity(x2y, id1, id2, measure)\n",
    "        return sorted(list(similarities.items()), key=lambda x:x[1], reverse = True)[:k]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('A3EBHHCZO6V2A4', 1.0),\n",
       " ('A3W4D8XOGLWUN5', 0.3898344204051092),\n",
       " ('A2KW2KWKABNYNO', 0.11413379669939978),\n",
       " ('A3E2FGR7OTA351', 0.07293721044789159),\n",
       " ('A1IIUCG9TJFUWS', 0.07257356561920973),\n",
       " ('A3NZQ0KTNYMVGL', 0.05532293677181463),\n",
       " ('A5HUEE1HB4LDF', 0.05405878626922568),\n",
       " ('ATO9DDJUGNWVD', 0.05343566363558953),\n",
       " ('A19DU0YV4K2MRY', 0.05238805435415342),\n",
       " ('AXTO23M29DQX0', 0.052085885694695855),\n",
       " ('A27YS4JDS7J3IC', 0.05166326946027823),\n",
       " ('A1NC5YN34N5VRX', 0.051033473626585724),\n",
       " ('A1BVI1R4GJMABC', 0.04639591260918303),\n",
       " ('A2VOI85H5S0OH6', 0.04395604395604396),\n",
       " ('ACY9QYNDFLVBI', 0.04368719712851072),\n",
       " ('A3E0962TERBW7F', 0.043376296235997876),\n",
       " ('A28IAZZI0SNRMW', 0.042378978884816045),\n",
       " ('A24N1BAS3CU27H', 0.04203625124338991),\n",
       " ('A280KHZO2L7GKA', 0.04203625124338991),\n",
       " ('AR65NXO4GIA9H', 0.041534557473541456),\n",
       " ('A2L7Z3FH4MSWYW', 0.041534557473541456),\n",
       " ('A1LVZI3QBCW9A0', 0.041534557473541456),\n",
       " ('ADN5YE0HOKE6O', 0.04123834724043112),\n",
       " ('A1QEWOSV05RYEO', 0.04119549418956575),\n",
       " ('A2NZ5UQQP3JCCN', 0.04116724000080964),\n",
       " ('A36EDWL4F3AASU', 0.04045529611502613),\n",
       " ('AUDSM2CTLLW1Q', 0.039856309287221295),\n",
       " ('ANRSF4BSFCRE7', 0.039722906114947866),\n",
       " ('AHSF06670DDN8', 0.03972290611494786),\n",
       " ('A35CHV6Z75D672', 0.0393275835802548),\n",
       " ('A9Q28YTLYREO7', 0.038945677494749156),\n",
       " ('A1K1Z8XHZLATOJ', 0.03885328440412798),\n",
       " ('A30Q1PK948KFZA', 0.03787430491671777),\n",
       " ('ANH7ENGKJU9D6', 0.03480472889955587),\n",
       " ('A20DZX38KRBIT8', 0.03444161731429479),\n",
       " ('A2WD3W8VV3RX5J', 0.0338057378163179),\n",
       " ('A1XNPOQDLLJJU3', 0.03296703296703296),\n",
       " ('A1PJVW2GSF73E7', 0.03296703296703296),\n",
       " ('A1LHAXBM5GBJS2', 0.03277367626722311),\n",
       " ('A13XGH1V3BQPJI', 0.032773676267223106),\n",
       " ('A2AJ76N7LS6GN0', 0.032467532467532464),\n",
       " ('A2U4PLAUZQOSCH', 0.03230096364109686),\n",
       " ('A3TGKOV5OEFI6V', 0.03230096364109686),\n",
       " ('A3LIOQ6M991VBX', 0.032213401200121235),\n",
       " ('A6XHF110BC856', 0.032213401200121235),\n",
       " ('AVKHYC2D7MD56', 0.03217933096192619),\n",
       " ('A3SWWXWV1WDZ68', 0.032028677629139725),\n",
       " ('A1LWOUFLMBW8CA', 0.03187595096160874),\n",
       " ('A2H0VLMRJEXOIG', 0.031698093286691674),\n",
       " ('A120RH58WVY4W6', 0.031698093286691674)]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_similarities(target: str, x2y: defaultdict, measure) -> dict:\n",
    "    similarities = dict()\n",
    "    for id1, id2 in product([target], user2product.keys()):\n",
    "        similarities[id2] = calculate_similarity(x2y, id1, id2, measure)\n",
    "    return sorted(list(similarities.items()), key=lambda x:x[1], reverse = True)[:50]\n",
    "\n",
    "\n",
    "find_similarities('A3EBHHCZO6V2A4', user2product, cosine_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
